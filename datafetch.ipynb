{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A web crawler is set up to pull sale data off of p24. \n",
    "# SET THE CSV FILE NAME IN LAST CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVDATA: (76, [[240000, 135, 'Melrose North'], [899000, 104, 'Klippoortje'], [720000, 97, 'Floracliffe'], [950000, 82, 'Hatfield'], [799000, 76, 'Klippoortje'], [650000, 84, 'Crowthorne AH'], [1150000, 84, 'Kyalami Hills'], [1696000, 99, 'Waterfall'], [895000, 104, 'Knysna Central'], [1495000, 81, 'Glen Austin AH'], [1020000, 48, 'Florida Park'], [12995, 140, 'Eastcliff'], [795000, 54, 'Chantelle'], [330000, 120, 'Bryanston'], [499000, 73, 'Bryanston'], [930000, 70, 'Norton Park'], [680000, 44, 'Halfway Gardens'], [700000, 92, 'New Redruth'], [380000, 342, 'Melrose'], [895000, 35, 'Johannesburg Central'], [500000, 114, 'Northgate'], [1375000, 34, 'Sandton Central'], [2189000, 83, 'Douglasdale'], [2450000, 56, 'Pretoria North'], [580000, 123, 'Alveda'], [1375000, 54, 'Kyalami Hills'], [680000, 47, 'Melrose North'], [650000, 36, 'Glen Austin AH'], [665000, 75, 'Sagewood'], [1495000, 84, 'Hatfield'], [1200000, 89, 'Rynfield'], [720000, 101, 'Eastcliff'], [330000, 135, 'Oakdene'], [795000, 76, 'Bryanston'], [760000, 99, 'Winchester Hills'], [820000, 120, 'Floracliffe'], [240000, 76, 'Knysna Central'], [420000, 104, 'Bryanston'], [899000, 58, 'Oakdene'], [710000, 50, 'Morningside'], [730000, 35, 'Eastcliff'], [1200000, 58, 'Sandringham'], [445000, 81, 'Solheim'], [820000, 101, 'Sandton Central'], [1150000, 84, 'Johannesburg Central'], [860000, 48, 'Greymont'], [1100000, 71, 'Paulshof'], [1150000, 34, 'Erand Gardens'], [1450000, 71, 'Glen Austin AH'], [12995, 110, 'Kyalami Hills'], [1490000, 84, 'Sandton Central'], [1990000, 68, 'Hatfield'], [835000, 89, 'Daspoort'], [650000, 50, 'Northgate'], [550000, 71, 'Halfway Gardens'], [590000, 43, 'Pretoria Central'], [450000, 117, 'Ferndale'], [690000, 84, 'Erand Gardens'], [1990000, 97, 'Florauna'], [470000, 87, 'Arcadia'], [1240000, 116, 'Waterfall'], [799000, 58, 'Norton Park'], [850000, 72, 'Sinoville'], [1450000, 110, 'Chantelle'], [795000, 61, 'Florauna'], [1240000, 61, 'Bryanston'], [1100000, 129, 'Kyalami Hills'], [695000, 68, 'Knysna Central'], [999000, 111, 'Pretoria Central'], [1250000, 57, 'Boksburg West'], [1190000, 114, 'Silverton'], [1100000, 114, 'Pretoria Gardens'], [630000, 207, 'Kempton Park Ext 4'], [730000, 116, 'Hyde Park'], [795000, 71, 'Hyde Park'], [930000, 120, 'Hatfield']])\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Define the number of pages\n",
    "num_iterations = 6\n",
    "\n",
    "pricelist = []\n",
    "sizelist = []\n",
    "locationlist = []\n",
    "\n",
    "#tqdm(range(num_iterations), desc=\"Scraping Progress\")\n",
    "\n",
    "# Create a tqdm progress bar\n",
    "for x in range(5):\n",
    "    p24 = f\"https://www.property24.com/apartments-for-sale/gauteng/1/p{x}\"\n",
    "    req = requests.get(p24)\n",
    "    soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "\n",
    "    for price in soup.find_all(\"span\", \"p24_price\"):\n",
    "        pricelist.append(price.text)   \n",
    "    \n",
    "    for size in soup.find_all(\"span\", \"p24_size\"):\n",
    "        sizelist.append(size.text)\n",
    "\n",
    "    for location in soup.find_all(\"span\", \"p24_location\"):\n",
    "        locationlist.append(location.text)\n",
    "\n",
    "pricelist = [price.strip().replace(\"\\n\", \"\").replace(\"\\r\", \"\").replace(\" \", \"\").replace(\"R\", \"\").replace(\"POA\", \"0\") for price in pricelist]  \n",
    "\n",
    "sizelist = [size.strip().replace(\"\\n\\n\", \"\").replace(\"m²\\n\", \"\").replace(\"m² \", \"\").replace(\" ha\", \"0\").replace(\" m²\", \"\").replace(\" \",  \"\").replace(\".\", \"\") for size in sizelist]  \n",
    "\n",
    "csvdata = [[int(addr), int(price), str(location)] for addr, price, location in set(zip(pricelist, sizelist, locationlist))]\n",
    "\n",
    "print(f\"CSVDATA: {len(csvdata), csvdata}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the propattr class the median and sd are calculated for the data. \n",
    "\n",
    "The data should be sorted by area name to avoid over use of the api. \n",
    "\n",
    "The data is sorted by name and pulled into its own list to find the co-ordinates using Bings Map Api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geocoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "commonlocations = []\n",
    "\n",
    "\n",
    "for data in csvdata:\n",
    "    if data[1] not in commonlocations:\n",
    "        commonlocations.append(data[1])\n",
    "\n",
    "print(f\"SIZE: {len(commonlocations)} {commonlocations}\")\n",
    "\n",
    "common_coords = []\n",
    "\n",
    "failed = []\n",
    "\n",
    "for addr in tqdm(commonlocations, desc=\"Finding Coordinates\"):\n",
    "    try:\n",
    "        g = geocoder.bing(f'{addr + \"northern cape\" + \"South Africa\"}', key=\"YOURKEY\")\n",
    "        \n",
    "        # Check if the geocoding request was successful\n",
    "        if g.ok:\n",
    "            results = g.json\n",
    "            common_coords.append([results[\"lat\"], results[\"lng\"], addr])\n",
    "        else:\n",
    "            # Handle the case where the geocoding request failed\n",
    "            print(f\"Geocoding request failed for address: {addr}\")\n",
    "            failed.append(addr)\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions that may occur during the geocoding request\n",
    "        print(f\"An error occurred while geocoding address: {addr}\")\n",
    "        print(f\"Error details: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter data into csv for locations, price and coords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Specify the target directory path\n",
    "target_directory = r'C:\\GitHub\\Land-value-GIS\\backups'\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "#if not os.path.exists(target_directory):\n",
    "#    os.makedirs(target_directory)\n",
    "\n",
    "# Define the file paths within the \"backups\" folder\n",
    "csvdata_file_path = os.path.join(target_directory, \"house_price_and_area_test.csv\")\n",
    "common_coords_file_path = os.path.join(target_directory, \"northern_cape_area_coords.csv\")\n",
    "\n",
    "# Write to \"prop_gauteng_locations_price.csv\"\n",
    "with open(csvdata_file_path, \"w\") as r:\n",
    "    writer = csv.writer(r)\n",
    "    writer.writerows(csvdata)\n",
    "\n",
    "# Write to \"gauteng_area_coords.csv\"\n",
    "#with open(common_coords_file_path, \"w\") as w:\n",
    "#    writer = csv.writer(w)\n",
    "#    writer.writerows(common_coords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the files into the backups dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
